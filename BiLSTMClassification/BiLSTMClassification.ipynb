{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xtSVOFjtty9X",
    "outputId": "ffe3478d-043b-459d-9791-89850d445c38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oZDgsKvFuCc8"
   },
   "outputs": [],
   "source": [
    "#You must have data set and Glove pretrained Glove Embedding matrxi in given path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Y0wnc4HuPmc",
    "outputId": "b6ac7013-cca6-44c2-f327-68dfaeffad48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 - 39s - loss: 0.6915 - accuracy: 0.5303 - val_loss: 0.6779 - val_accuracy: 0.6291 - 39s/epoch - 752ms/step\n",
      "Epoch 2/3\n",
      "52/52 - 28s - loss: 0.6549 - accuracy: 0.6187 - val_loss: 0.6203 - val_accuracy: 0.6651 - 28s/epoch - 535ms/step\n",
      "Epoch 3/3\n",
      "52/52 - 29s - loss: 0.5508 - accuracy: 0.7218 - val_loss: 0.5927 - val_accuracy: 0.7071 - 29s/epoch - 558ms/step\n",
      "Epoch 1/3\n",
      "52/52 - 34s - loss: 0.4217 - accuracy: 0.8134 - val_loss: 0.5375 - val_accuracy: 0.7431 - 34s/epoch - 651ms/step\n",
      "Epoch 2/3\n",
      "52/52 - 28s - loss: 0.2952 - accuracy: 0.8813 - val_loss: 0.5319 - val_accuracy: 0.7875 - 28s/epoch - 544ms/step\n",
      "Epoch 3/3\n",
      "52/52 - 29s - loss: 0.1763 - accuracy: 0.9324 - val_loss: 0.6042 - val_accuracy: 0.7959 - 29s/epoch - 552ms/step\n",
      "Epoch 1/3\n",
      "52/52 - 29s - loss: 0.1221 - accuracy: 0.9546 - val_loss: 0.6858 - val_accuracy: 0.8019 - 29s/epoch - 550ms/step\n",
      "Epoch 2/3\n",
      "52/52 - 29s - loss: 0.0748 - accuracy: 0.9718 - val_loss: 0.6480 - val_accuracy: 0.8403 - 29s/epoch - 552ms/step\n",
      "Epoch 3/3\n",
      "52/52 - 26s - loss: 0.0762 - accuracy: 0.9724 - val_loss: 0.6366 - val_accuracy: 0.8427 - 26s/epoch - 502ms/step\n",
      "Epoch 1/3\n",
      "52/52 - 29s - loss: 0.0411 - accuracy: 0.9871 - val_loss: 0.7836 - val_accuracy: 0.8235 - 29s/epoch - 551ms/step\n",
      "Epoch 2/3\n",
      "52/52 - 29s - loss: 0.0171 - accuracy: 0.9964 - val_loss: 0.8068 - val_accuracy: 0.8427 - 29s/epoch - 564ms/step\n",
      "Epoch 3/3\n",
      "52/52 - 29s - loss: 0.0144 - accuracy: 0.9955 - val_loss: 1.0611 - val_accuracy: 0.8307 - 29s/epoch - 556ms/step\n",
      "Epoch 1/3\n",
      "52/52 - 29s - loss: 0.0225 - accuracy: 0.9931 - val_loss: 0.7317 - val_accuracy: 0.8559 - 29s/epoch - 560ms/step\n",
      "Epoch 2/3\n",
      "52/52 - 29s - loss: 0.0548 - accuracy: 0.9772 - val_loss: 0.7616 - val_accuracy: 0.8259 - 29s/epoch - 548ms/step\n",
      "Epoch 3/3\n",
      "52/52 - 26s - loss: 0.0310 - accuracy: 0.9889 - val_loss: 0.9363 - val_accuracy: 0.8223 - 26s/epoch - 496ms/step\n",
      "33/33 - 3s - loss: 0.9706 - accuracy: 0.8165 - 3s/epoch - 89ms/step\n",
      "33/33 [==============================] - 7s 127ms/step\n",
      "Final Precision = 0.7690, Recall = 0.9014, F1-score = 0.8299\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.utils import resample\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv(\"/content/gdrive/MyDrive/TweetDS/train.csv\")\n",
    "data['tweet'] = data['tweet'].astype(str)\n",
    "\n",
    "# Tokenize the text data\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data['tweet'])\n",
    "X = tokenizer.texts_to_sequences(data['tweet'])\n",
    "X = pad_sequences(X, maxlen=100)\n",
    "y = data['sarcastic']\n",
    "\n",
    "# Oversample the minority class\n",
    "data_majority = data[data.sarcastic == 0]\n",
    "data_minority = data[data.sarcastic == 1]\n",
    "data_minority_upsampled = resample(data_minority, replace=True, n_samples=len(data_majority), random_state=42)\n",
    "data_upsampled = pd.concat([data_majority, data_minority_upsampled])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_upsampled = tokenizer.texts_to_sequences(data_upsampled['tweet'])\n",
    "X_upsampled = pad_sequences(X_upsampled, maxlen=100)\n",
    "y_upsampled = data_upsampled['sarcastic']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_upsampled, y_upsampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Load pre-trained GloVe word vectors\n",
    "embedding_dim = 300\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "glove_path = \"/content/gdrive/MyDrive/PreTrainedModels/GloVe/glove.6B.300d.txt\"\n",
    "embeddings_index = {}\n",
    "with open(glove_path, encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype=\"float32\")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "# Create an embedding matrix for the Embedding layer\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "# Build the LSTM model with GloVe embeddings\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim,\n",
    "                    input_length=100, weights=[embedding_matrix], trainable=False))\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model with Adam optimizer\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "# Implement early stopping and model checkpoint\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True, mode='max')\n",
    "model_checkpoint = ModelCheckpoint(\"/content/gdrive/MyDrive/MyModels/sarcasm_detection_best_model.h5\", save_best_only=True)\n",
    "\n",
    "# Train the model and calculate metrics for each epoch\n",
    "for iteration in range(5):\n",
    "    history = model.fit(X_train, y_train, validation_split=0.2,\n",
    "                        epochs=3, batch_size=64, callbacks=[early_stopping, model_checkpoint], verbose=2)\n",
    "\n",
    "# Evaluate the model on the testing data\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "\n",
    "# Calculate final metrics for the best model\n",
    "final_precision = precision_score(y_test, y_pred)\n",
    "final_recall = recall_score(y_test, y_pred)\n",
    "final_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f'Final Precision = {final_precision:.4f}, Recall = {final_recall:.4f}, F1-score = {final_f1:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P1dGvAwFvGum",
    "outputId": "010f816e-7e6e-4ff0-ee31-9b9f6978f2e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 102ms/step\n",
      "The sentence is sarcastic.\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the input sentence\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = ''.join([char for char in text if char not in string.punctuation])\n",
    "    return text\n",
    "\n",
    "# Example input sentence\n",
    "input_sentence = \"Congratulations! Your ability to state the obvious is truly remarkable\"\n",
    "\n",
    "# Preprocess the input sentence\n",
    "input_sentence = preprocess_text(input_sentence)\n",
    "\n",
    "# Tokenize and pad the preprocessed sentence\n",
    "input_sequence = tokenizer.texts_to_sequences([input_sentence])\n",
    "input_sequence = pad_sequences(input_sequence, maxlen=100)\n",
    "\n",
    "# Predict the sentiment of the input sentence\n",
    "prediction = (model.predict(input_sequence) > 0.5).astype(int)[0][0]\n",
    "\n",
    "# Interpret the prediction\n",
    "if prediction == 1:\n",
    "    print(\"The sentence is sarcastic.\")\n",
    "else:\n",
    "    print(\"The sentence is not sarcastic.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qgWvTw-F7Ml_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
