{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRvF2Lfz1zp4",
        "outputId": "26e61b53-e0b1-4e0e-eaf8-de06d93dd823"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls /content/drive/MyDrive/\n"
      ],
      "metadata": {
        "id": "NMmOzD9kGTw9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "879b3bb7-5c62-4a24-f057-72a038914455"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "BertDemo.ipynb\t       BiLSTMClassification.ipynb  Image_Downloader  Resume.pdf\n",
            "BiLSTM_BERT_Train.csv  glove.6B.300d.txt.zip\t   MyModels\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/drive/MyDrive/\n"
      ],
      "metadata": {
        "id": "-5OWzJpV260n"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/glove.6B.300d.txt.zip -d /content/drive/MyDrive/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9j2N7txb3BAQ",
        "outputId": "dd8f2122-49f9-4f56-f04b-670224ecb7d7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/glove.6B.300d.txt.zip\n",
            "  inflating: /content/drive/MyDrive/glove.6B.300d.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZDgsKvFuCc8"
      },
      "outputs": [],
      "source": [
        "#You must have data set and Glove pretrained Glove Embedding matrxi in given path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Y0wnc4HuPmc",
        "outputId": "72202c5a-01c1-410c-d658-74d31a947567"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Epoch 1/3\n",
            "52/52 - 10s - loss: 0.6894 - accuracy: 0.5352 - val_loss: 0.6658 - val_accuracy: 0.6471 - 10s/epoch - 188ms/step\n",
            "Epoch 2/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 - 1s - loss: 0.6342 - accuracy: 0.6445 - val_loss: 0.6096 - val_accuracy: 0.6687 - 1s/epoch - 21ms/step\n",
            "Epoch 3/3\n",
            "52/52 - 1s - loss: 0.5259 - accuracy: 0.7395 - val_loss: 0.5689 - val_accuracy: 0.7059 - 1s/epoch - 22ms/step\n",
            "Epoch 1/3\n",
            "52/52 - 2s - loss: 0.3957 - accuracy: 0.8320 - val_loss: 0.5438 - val_accuracy: 0.7455 - 2s/epoch - 35ms/step\n",
            "Epoch 2/3\n",
            "52/52 - 1s - loss: 0.2575 - accuracy: 0.8978 - val_loss: 0.6280 - val_accuracy: 0.7611 - 966ms/epoch - 19ms/step\n",
            "Epoch 3/3\n",
            "52/52 - 1s - loss: 0.1815 - accuracy: 0.9279 - val_loss: 0.5551 - val_accuracy: 0.7971 - 966ms/epoch - 19ms/step\n",
            "Epoch 1/3\n",
            "52/52 - 1s - loss: 0.1251 - accuracy: 0.9546 - val_loss: 0.8354 - val_accuracy: 0.7575 - 995ms/epoch - 19ms/step\n",
            "Epoch 2/3\n",
            "52/52 - 1s - loss: 0.0765 - accuracy: 0.9748 - val_loss: 0.6933 - val_accuracy: 0.8295 - 946ms/epoch - 18ms/step\n",
            "Epoch 3/3\n",
            "52/52 - 1s - loss: 0.0468 - accuracy: 0.9856 - val_loss: 0.7574 - val_accuracy: 0.8247 - 935ms/epoch - 18ms/step\n",
            "Epoch 1/3\n",
            "52/52 - 1s - loss: 0.0359 - accuracy: 0.9889 - val_loss: 1.1838 - val_accuracy: 0.7815 - 1s/epoch - 21ms/step\n",
            "Epoch 2/3\n",
            "52/52 - 1s - loss: 0.0318 - accuracy: 0.9904 - val_loss: 1.0968 - val_accuracy: 0.7947 - 940ms/epoch - 18ms/step\n",
            "Epoch 3/3\n",
            "52/52 - 1s - loss: 0.0210 - accuracy: 0.9931 - val_loss: 0.8071 - val_accuracy: 0.8535 - 1s/epoch - 21ms/step\n",
            "Epoch 1/3\n",
            "52/52 - 1s - loss: 0.0182 - accuracy: 0.9943 - val_loss: 0.8522 - val_accuracy: 0.8319 - 1s/epoch - 21ms/step\n",
            "Epoch 2/3\n",
            "52/52 - 1s - loss: 0.0095 - accuracy: 0.9979 - val_loss: 1.0309 - val_accuracy: 0.8343 - 913ms/epoch - 18ms/step\n",
            "Epoch 3/3\n",
            "52/52 - 1s - loss: 0.0202 - accuracy: 0.9931 - val_loss: 1.3240 - val_accuracy: 0.7719 - 897ms/epoch - 17ms/step\n",
            "33/33 - 0s - loss: 1.3475 - accuracy: 0.7771 - 349ms/epoch - 11ms/step\n",
            "33/33 [==============================] - 1s 7ms/step\n",
            "Final Precision = 0.7117, Recall = 0.9265, F1-score = 0.8050\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.utils import resample\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create directory for saving models\n",
        "!mkdir -p /content/drive/MyDrive/MyModels/\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/BiLSTM_BERT_Train.csv\")\n",
        "data['tweet'] = data['tweet'].astype(str)\n",
        "\n",
        "# Tokenize the text data\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(data['tweet'])\n",
        "X = tokenizer.texts_to_sequences(data['tweet'])\n",
        "X = pad_sequences(X, maxlen=100)\n",
        "y = data['sarcastic']\n",
        "\n",
        "# Oversample the minority class\n",
        "data_majority = data[data.sarcastic == 0]\n",
        "data_minority = data[data.sarcastic == 1]\n",
        "data_minority_upsampled = resample(data_minority, replace=True, n_samples=len(data_majority), random_state=42)\n",
        "data_upsampled = pd.concat([data_majority, data_minority_upsampled])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_upsampled = tokenizer.texts_to_sequences(data_upsampled['tweet'])\n",
        "X_upsampled = pad_sequences(X_upsampled, maxlen=100)\n",
        "y_upsampled = data_upsampled['sarcastic']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_upsampled, y_upsampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Load pre-trained GloVe word vectors\n",
        "embedding_dim = 300\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "glove_path = \"/content/drive/MyDrive/glove.6B.300d.txt\"\n",
        "embeddings_index = {}\n",
        "with open(glove_path, encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype=\"float32\")\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "# Create an embedding matrix for the Embedding layer\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "# Build the LSTM model with GloVe embeddings\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim,\n",
        "                    input_length=100, weights=[embedding_matrix], trainable=False))\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(64)))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model with Adam optimizer\n",
        "model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
        "\n",
        "# Implement early stopping and model checkpoint\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True, mode='max')\n",
        "model_checkpoint = ModelCheckpoint(\"/content/drive/MyDrive/MyModels/sarcasm_detection_best_model.h5\", save_best_only=True)\n",
        "\n",
        "# Train the model and calculate metrics for each epoch\n",
        "for iteration in range(5):\n",
        "    history = model.fit(X_train, y_train, validation_split=0.2,\n",
        "                        epochs=3, batch_size=64, callbacks=[early_stopping, model_checkpoint], verbose=2)\n",
        "\n",
        "# Evaluate the model on the testing data\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
        "\n",
        "# Calculate final metrics for the best model\n",
        "final_precision = precision_score(y_test, y_pred)\n",
        "final_recall = recall_score(y_test, y_pred)\n",
        "final_f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f'Final Precision = {final_precision:.4f}, Recall = {final_recall:.4f}, F1-score = {final_f1:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1dGvAwFvGum",
        "outputId": "c9a28d8e-8627-48b8-979f-a603bb762ddb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 35ms/step\n",
            "The sentence is sarcastic.\n"
          ]
        }
      ],
      "source": [
        "# Preprocess the input sentence\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = ''.join([char for char in text if char not in string.punctuation])\n",
        "    return text\n",
        "\n",
        "# Example input sentence\n",
        "# input_sentence = \"Congratulations! Your ability to state the obvious is truly remarkable\"   #not sarcastic\n",
        "input_sentence = \"Oh wow, you figured that out all by yourself? You're a real genius.\"  #sarcastic\n",
        "\n",
        "\n",
        "# Preprocess the input sentence\n",
        "input_sentence = preprocess_text(input_sentence)\n",
        "\n",
        "# Tokenize and pad the preprocessed sentence\n",
        "input_sequence = tokenizer.texts_to_sequences([input_sentence])\n",
        "input_sequence = pad_sequences(input_sequence, maxlen=100)\n",
        "\n",
        "# Predict the sentiment of the input sentence\n",
        "prediction = (model.predict(input_sequence) > 0.5).astype(int)[0][0]\n",
        "\n",
        "# Interpret the prediction\n",
        "if prediction == 1:\n",
        "    print(\"The sentence is sarcastic.\")\n",
        "else:\n",
        "    print(\"The sentence is not sarcastic.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgWvTw-F7Ml_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}